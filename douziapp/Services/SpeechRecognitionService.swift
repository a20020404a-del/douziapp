//
//  SpeechRecognitionService.swift
//  douziapp
//
//  Apple Speech Frameworkã‚’ä½¿ç”¨ã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°èªè­˜
//

import Foundation
import Speech
import AVFoundation

@MainActor
class SpeechRecognitionService: ObservableObject {
    // MARK: - Published Properties

    @Published var recognizedText: String = ""
    @Published var isListening: Bool = false
    @Published var errorMessage: String = ""
    @Published var authorizationStatus: String = "æœªç¢ºèª"

    // MARK: - Private Properties

    private var speechRecognizer: SFSpeechRecognizer?
    private var recognitionRequest: SFSpeechAudioBufferRecognitionRequest?
    private var recognitionTask: SFSpeechRecognitionTask?
    private var audioEngine: AVAudioEngine?

    // MARK: - Initialization

    private var currentLocale: String = "en-US"

    init() {
        speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: "en-US"))
        audioEngine = AVAudioEngine()
    }

    /// èªè­˜è¨€èªã‚’å¤‰æ›´
    func setLanguage(_ localeIdentifier: String) {
        currentLocale = localeIdentifier
        speechRecognizer = SFSpeechRecognizer(locale: Locale(identifier: localeIdentifier))
        print("ğŸŒ éŸ³å£°èªè­˜è¨€èªã‚’å¤‰æ›´: \(localeIdentifier)")
    }

    // MARK: - Public Methods

    /// ãƒã‚¤ã‚¯ã¨éŸ³å£°èªè­˜ã®æ¨©é™ã‚’ä¸¡æ–¹ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
    func requestAuthorization() async -> Bool {
        // 1. ãƒã‚¤ã‚¯æ¨©é™ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        let micGranted = await requestMicrophonePermission()
        if !micGranted {
            errorMessage = "ãƒã‚¤ã‚¯ã®æ¨©é™ãŒå¿…è¦ã§ã™"
            authorizationStatus = "ãƒã‚¤ã‚¯æ‹’å¦"
            return false
        }

        // 2. éŸ³å£°èªè­˜æ¨©é™ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
        let speechGranted = await requestSpeechPermission()
        if !speechGranted {
            errorMessage = "éŸ³å£°èªè­˜ã®æ¨©é™ãŒå¿…è¦ã§ã™"
            authorizationStatus = "éŸ³å£°èªè­˜æ‹’å¦"
            return false
        }

        authorizationStatus = "è¨±å¯æ¸ˆã¿"
        return true
    }

    private func requestMicrophonePermission() async -> Bool {
        await withCheckedContinuation { continuation in
            AVAudioApplication.requestRecordPermission { granted in
                continuation.resume(returning: granted)
            }
        }
    }

    private func requestSpeechPermission() async -> Bool {
        await withCheckedContinuation { continuation in
            SFSpeechRecognizer.requestAuthorization { status in
                continuation.resume(returning: status == .authorized)
            }
        }
    }

    /// éŸ³å£°èªè­˜ã‚’é–‹å§‹
    func startListening() throws {
        // ãƒªã‚»ãƒƒãƒˆ
        stopListening()
        errorMessage = ""
        recognizedText = ""

        // æ–°ã—ã„AudioEngineã‚’ä½œæˆ
        audioEngine = AVAudioEngine()
        guard let audioEngine = audioEngine else {
            throw SpeechError.audioEngineError
        }

        // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è¨­å®š
        let audioSession = AVAudioSession.sharedInstance()
        do {
            try audioSession.setCategory(.playAndRecord, mode: .measurement, options: [.defaultToSpeaker, .allowBluetooth])
            try audioSession.setActive(true, options: .notifyOthersOnDeactivation)
        } catch {
            errorMessage = "ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)"
            throw SpeechError.audioSessionError
        }

        // èªè­˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ä½œæˆ
        recognitionRequest = SFSpeechAudioBufferRecognitionRequest()
        guard let recognitionRequest = recognitionRequest else {
            throw SpeechError.requestCreationFailed
        }

        recognitionRequest.shouldReportPartialResults = true
        recognitionRequest.requiresOnDeviceRecognition = false

        // èªè­˜ã‚¿ã‚¹ã‚¯ã®é–‹å§‹
        guard let speechRecognizer = speechRecognizer else {
            errorMessage = "éŸ³å£°èªè­˜ãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“"
            throw SpeechError.recognizerUnavailable
        }

        if !speechRecognizer.isAvailable {
            errorMessage = "éŸ³å£°èªè­˜ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
            throw SpeechError.recognizerUnavailable
        }

        recognitionTask = speechRecognizer.recognitionTask(with: recognitionRequest) { [weak self] result, error in
            Task { @MainActor in
                guard let self = self else { return }

                if let result = result {
                    self.recognizedText = result.bestTranscription.formattedString
                    print("èªè­˜çµæœ: \(self.recognizedText)")
                }

                if let error = error {
                    // èªè­˜ãŒçµ‚äº†ã—ãŸå ´åˆã®ã‚¨ãƒ©ãƒ¼ã¯ç„¡è¦–
                    let nsError = error as NSError
                    if nsError.domain == "kAFAssistantErrorDomain" && nsError.code == 1110 {
                        // éŸ³å£°å…¥åŠ›ãŒãªã‹ã£ãŸå ´åˆ - æ­£å¸¸
                        return
                    }
                    self.errorMessage = "èªè­˜ã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)"
                    print("èªè­˜ã‚¨ãƒ©ãƒ¼: \(error)")
                }
            }
        }

        // ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªå…¥åŠ›ã®è¨­å®š
        let inputNode = audioEngine.inputNode
        let recordingFormat = inputNode.outputFormat(forBus: 0)

        // ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãŒæœ‰åŠ¹ã‹ç¢ºèª
        guard recordingFormat.sampleRate > 0 else {
            errorMessage = "ç„¡åŠ¹ãªã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"
            throw SpeechError.audioEngineError
        }

        inputNode.installTap(onBus: 0, bufferSize: 1024, format: recordingFormat) { [weak self] buffer, _ in
            self?.recognitionRequest?.append(buffer)
        }

        do {
            audioEngine.prepare()
            try audioEngine.start()
            isListening = true
            print("éŸ³å£°èªè­˜é–‹å§‹")
        } catch {
            errorMessage = "ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¨ãƒ³ã‚¸ãƒ³èµ·å‹•ã‚¨ãƒ©ãƒ¼: \(error.localizedDescription)"
            throw SpeechError.audioEngineError
        }
    }

    /// éŸ³å£°èªè­˜ã‚’åœæ­¢
    func stopListening() {
        audioEngine?.stop()
        audioEngine?.inputNode.removeTap(onBus: 0)

        recognitionRequest?.endAudio()
        recognitionRequest = nil

        recognitionTask?.cancel()
        recognitionTask = nil

        isListening = false
        print("éŸ³å£°èªè­˜åœæ­¢")
    }

    /// èªè­˜ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢
    func clearText() {
        recognizedText = ""
        errorMessage = ""
    }
}

// MARK: - Error Types

enum SpeechError: LocalizedError {
    case notAuthorized
    case recognizerUnavailable
    case requestCreationFailed
    case audioSessionError
    case audioEngineError

    var errorDescription: String? {
        switch self {
        case .notAuthorized:
            return "éŸ³å£°èªè­˜ãŒè¨±å¯ã•ã‚Œã¦ã„ã¾ã›ã‚“"
        case .recognizerUnavailable:
            return "éŸ³å£°èªè­˜ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“"
        case .requestCreationFailed:
            return "èªè­˜ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ"
        case .audioSessionError:
            return "ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼"
        case .audioEngineError:
            return "ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¨ãƒ³ã‚¸ãƒ³ã‚¨ãƒ©ãƒ¼"
        }
    }
}
