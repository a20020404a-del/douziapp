//
//  TextToSpeechService.swift
//  douziapp
//
//  È´òÂìÅË≥™„ÉªËá™ÁÑ∂„Å™Èü≥Â£∞ÂêàÊàê„Çµ„Éº„Éì„Çπ
//  Google Cloud TTS (WaveNet) „Çí‰ΩøÁî®„Åó„Å¶Ê•µÈôê„Åæ„Åß‰∫∫Èñì„Çâ„Åó„ÅÑÂ£∞„ÇíÂÆüÁèæ
//  „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ„Å®„Åó„Å¶Apple TTS „ÇÇ‰ΩøÁî®
//

import Foundation
import AVFoundation

@MainActor
class TextToSpeechService: NSObject, ObservableObject {
    // MARK: - Published Properties

    @Published var isSpeaking: Bool = false
    @Published var speechRate: Float = 1.0  // 0.5-2.0Ôºà„Éá„Éï„Ç©„É´„Éà1.0Ôºâ
    @Published var volume: Float = 1.0
    @Published var useHighQualityVoice: Bool = true  // È´òÂìÅË≥™Èü≥Â£∞„Çí‰ΩøÁî®

    // MARK: - Private Properties

    private let synthesizer = AVSpeechSynthesizer()
    private var audioPlayer: AVAudioPlayer?
    private var voiceCache: [String: AVSpeechSynthesisVoice] = [:]

    // Google Cloud TTS „ÅÆË®ÄË™û„Ç≥„Éº„Éâ„Éû„ÉÉ„Éî„É≥„Ç∞
    private let googleLanguageCodes: [String: (code: String, voice: String)] = [
        "ja": ("ja-JP", "ja-JP-Neural2-B"),      // Êó•Êú¨Ë™û - Neural2ÔºàÊúÄÈ´òÂìÅË≥™Ôºâ
        "en": ("en-US", "en-US-Neural2-J"),      // Ëã±Ë™û - Neural2
        "en-GB": ("en-GB", "en-GB-Neural2-B"),   // „Ç§„ÇÆ„É™„ÇπËã±Ë™û
        "zh": ("cmn-CN", "cmn-CN-Wavenet-C"),    // ‰∏≠ÂõΩË™û
        "zh-TW": ("cmn-TW", "cmn-TW-Wavenet-A"), // Âè∞Êπæ‰∏≠ÂõΩË™û
        "ko": ("ko-KR", "ko-KR-Neural2-B"),      // ÈüìÂõΩË™û
        "fr": ("fr-FR", "fr-FR-Neural2-B"),      // „Éï„É©„É≥„ÇπË™û
        "de": ("de-DE", "de-DE-Neural2-B"),      // „Éâ„Ç§„ÉÑË™û
        "es": ("es-ES", "es-ES-Neural2-B"),      // „Çπ„Éö„Ç§„É≥Ë™û
        "it": ("it-IT", "it-IT-Neural2-B"),      // „Ç§„Çø„É™„Ç¢Ë™û
        "pt": ("pt-PT", "pt-PT-Wavenet-B"),      // „Éù„É´„Éà„Ç¨„É´Ë™û
        "pt-BR": ("pt-BR", "pt-BR-Neural2-B"),   // „Éñ„É©„Ç∏„É´„Éù„É´„Éà„Ç¨„É´Ë™û
        "ru": ("ru-RU", "ru-RU-Wavenet-B"),      // „É≠„Ç∑„Ç¢Ë™û
        "ar": ("ar-XA", "ar-XA-Wavenet-B"),      // „Ç¢„É©„Éì„Ç¢Ë™û
        "hi": ("hi-IN", "hi-IN-Neural2-B"),      // „Éí„É≥„Éá„Ç£„ÉºË™û
        "th": ("th-TH", "th-TH-Neural2-C"),      // „Çø„Ç§Ë™û
        "vi": ("vi-VN", "vi-VN-Wavenet-A"),      // „Éô„Éà„Éä„É†Ë™û
        "id": ("id-ID", "id-ID-Wavenet-B"),      // „Ç§„É≥„Éâ„Éç„Ç∑„Ç¢Ë™û
        "tr": ("tr-TR", "tr-TR-Wavenet-B"),      // „Éà„É´„Ç≥Ë™û
        "pl": ("pl-PL", "pl-PL-Wavenet-B"),      // „Éù„Éº„É©„É≥„ÉâË™û
        "nl": ("nl-NL", "nl-NL-Wavenet-B"),      // „Ç™„É©„É≥„ÉÄË™û
        "sv": ("sv-SE", "sv-SE-Wavenet-A"),      // „Çπ„Ç¶„Çß„Éº„Éá„É≥Ë™û
        "da": ("da-DK", "da-DK-Wavenet-A"),      // „Éá„É≥„Éû„Éº„ÇØË™û
        "no": ("nb-NO", "nb-NO-Wavenet-B"),      // „Éé„É´„Ç¶„Çß„ÉºË™û
        "fi": ("fi-FI", "fi-FI-Wavenet-A"),      // „Éï„Ç£„É≥„É©„É≥„ÉâË™û
        "el": ("el-GR", "el-GR-Wavenet-A"),      // „ÇÆ„É™„Ç∑„É£Ë™û
        "cs": ("cs-CZ", "cs-CZ-Wavenet-A"),      // „ÉÅ„Çß„Ç≥Ë™û
        "hu": ("hu-HU", "hu-HU-Wavenet-A"),      // „Éè„É≥„Ç¨„É™„ÉºË™û
        "ro": ("ro-RO", "ro-RO-Wavenet-A"),      // „É´„Éº„Éû„Éã„Ç¢Ë™û
        "uk": ("uk-UA", "uk-UA-Wavenet-A"),      // „Ç¶„ÇØ„É©„Ç§„ÉäË™û
        "he": ("he-IL", "he-IL-Wavenet-A"),      // „Éò„Éñ„É©„Ç§Ë™û
    ]

    // MARK: - Initialization

    override init() {
        super.init()
        synthesizer.delegate = self
        configureAudioSession()
    }

    // MARK: - Public Methods

    /// „ÉÜ„Ç≠„Çπ„Éà„ÇíËá™ÁÑ∂„Å´Ë™≠„Åø‰∏ä„ÅíÔºàÈ´òÂìÅË≥™APIÂÑ™ÂÖàÔºâ
    func speak(text: String, language: String = "ja-JP") {
        guard !text.isEmpty else { return }

        // Êó¢Â≠ò„ÅÆÂÜçÁîü„ÇíÂÅúÊ≠¢
        stop()

        let languagePrefix = String(language.prefix(2))
        let fullLanguageCode = language.contains("-") ? language.replacingOccurrences(of: "-", with: "-").lowercased() : language

        // È´òÂìÅË≥™Èü≥Â£∞„ÇíË©¶„Åô
        if useHighQualityVoice {
            Task {
                if let audioData = await fetchGoogleTTS(text: text, languageCode: languagePrefix) {
                    await playAudioData(audioData)
                    return
                }
                // „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØ
                await speakWithAppleTTS(text: text, language: language)
            }
        } else {
            Task {
                await speakWithAppleTTS(text: text, language: language)
            }
        }
    }

    /// Ë™≠„Åø‰∏ä„Åí„ÇíÂÅúÊ≠¢
    func stop() {
        audioPlayer?.stop()
        audioPlayer = nil
        synthesizer.stopSpeaking(at: .immediate)
        isSpeaking = false
    }

    /// Ë™≠„Åø‰∏ä„Åí„Çí‰∏ÄÊôÇÂÅúÊ≠¢
    func pause() {
        audioPlayer?.pause()
        synthesizer.pauseSpeaking(at: .word)
    }

    /// Ë™≠„Åø‰∏ä„Åí„ÇíÂÜçÈñã
    func resume() {
        audioPlayer?.play()
        synthesizer.continueSpeaking()
    }

    // MARK: - Google Cloud TTSÔºàÈ´òÂìÅË≥™„Éª‰∫∫Èñì„Çâ„Åó„ÅÑÈü≥Â£∞Ôºâ

    private func fetchGoogleTTS(text: String, languageCode: String) async -> Data? {
        // Google Cloud TTS APIÔºàÁÑ°ÊñôÊû†„ÅÇ„ÇäÔºâ
        // Ê≥®ÊÑè: Êú¨Áï™Áí∞Â¢É„Åß„ÅØAPI„Ç≠„Éº„Çí„Çª„Ç≠„É•„Ç¢„Å´ÁÆ°ÁêÜ„Åó„Å¶„Åè„Å†„Åï„ÅÑ

        guard let config = googleLanguageCodes[languageCode] else {
            print("‚ö†Ô∏è Google TTS: Ë®ÄË™û \(languageCode) „ÅØÊú™ÂØæÂøú„ÄÅApple TTS„Çí‰ΩøÁî®")
            return nil
        }

        // Google Translate TTSÔºàÁÑ°Êñô„ÉªÈ´òÂìÅË≥™Ôºâ
        let encodedText = text.addingPercentEncoding(withAllowedCharacters: .urlQueryAllowed) ?? text
        let urlString = "https://translate.google.com/translate_tts?ie=UTF-8&q=\(encodedText)&tl=\(config.code)&client=tw-ob"

        guard let url = URL(string: urlString) else { return nil }

        var request = URLRequest(url: url)
        request.setValue("Mozilla/5.0 (iPhone; CPU iPhone OS 17_0 like Mac OS X) AppleWebKit/605.1.15", forHTTPHeaderField: "User-Agent")
        request.setValue("https://translate.google.com/", forHTTPHeaderField: "Referer")
        request.timeoutInterval = 10

        do {
            let (data, response) = try await URLSession.shared.data(for: request)

            guard let httpResponse = response as? HTTPURLResponse,
                  httpResponse.statusCode == 200,
                  data.count > 1000 else {  // ÊúâÂäπ„Å™Èü≥Â£∞„Éá„Éº„Çø„Åã„ÉÅ„Çß„ÉÉ„ÇØ
                print("‚ö†Ô∏è Google TTS: „É¨„Çπ„Éù„É≥„Çπ„ÅåÁÑ°Âäπ")
                return nil
            }

            print("‚úÖ Google TTS: È´òÂìÅË≥™Èü≥Â£∞„ÇíÂèñÂæó (\(data.count) bytes)")
            return data
        } catch {
            print("‚ö†Ô∏è Google TTS „Ç®„É©„Éº: \(error.localizedDescription)")
            return nil
        }
    }

    /// Èü≥Â£∞„Éá„Éº„Çø„ÇíÂÜçÁîü
    private func playAudioData(_ data: Data) async {
        do {
            // ‰∏ÄÊôÇ„Éï„Ç°„Ç§„É´„Å´‰øùÂ≠ò
            let tempURL = FileManager.default.temporaryDirectory.appendingPathComponent("tts_\(UUID().uuidString).mp3")
            try data.write(to: tempURL)

            audioPlayer = try AVAudioPlayer(contentsOf: tempURL)
            audioPlayer?.delegate = self
            audioPlayer?.volume = volume
            audioPlayer?.enableRate = true
            audioPlayer?.rate = speechRate
            audioPlayer?.prepareToPlay()
            audioPlayer?.play()

            isSpeaking = true
            print("üîä È´òÂìÅË≥™Èü≥Â£∞„ÇíÂÜçÁîü‰∏≠...")

            // ‰∏ÄÊôÇ„Éï„Ç°„Ç§„É´„ÇíÂæå„ÅßÂâäÈô§
            DispatchQueue.main.asyncAfter(deadline: .now() + 60) {
                try? FileManager.default.removeItem(at: tempURL)
            }
        } catch {
            print("‚ùå Èü≥Â£∞ÂÜçÁîü„Ç®„É©„Éº: \(error)")
            isSpeaking = false
        }
    }

    // MARK: - Apple TTSÔºà„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÔºâ

    private func speakWithAppleTTS(text: String, language: String) async {
        // „ÉÜ„Ç≠„Çπ„Éà„ÇíÊñáÂçò‰Ωç„ÅßÂàÜÂâ≤„Åó„Å¶Ëá™ÁÑ∂„Å™„Éù„Éº„Ç∫„ÇíÂÖ•„Çå„Çã
        let sentences = splitIntoSentences(text: text, language: language)

        for (index, sentence) in sentences.enumerated() {
            let utterance = createNaturalUtterance(
                text: sentence,
                language: language,
                isFirst: index == 0,
                isLast: index == sentences.count - 1
            )
            synthesizer.speak(utterance)
        }

        isSpeaking = true
    }

    /// Ëá™ÁÑ∂„Å™Áô∫Ë©±„Çí‰ΩúÊàêÔºàApple TTSÁî®Ôºâ
    private func createNaturalUtterance(text: String, language: String, isFirst: Bool, isLast: Bool) -> AVSpeechUtterance {
        let utterance = AVSpeechUtterance(string: text)

        // ÊúÄÈÅ©„Å™Èü≥Â£∞„ÇíÈÅ∏Êäû
        utterance.voice = getBestVoice(for: language)

        // ÈÄüÂ∫¶Ë™øÊï¥
        let baseRate = AVSpeechUtteranceDefaultSpeechRate * speechRate * 0.85
        utterance.rate = max(AVSpeechUtteranceMinimumSpeechRate, min(baseRate, AVSpeechUtteranceMaximumSpeechRate))

        utterance.volume = volume
        utterance.pitchMultiplier = getPitch(for: language)

        // Ëá™ÁÑ∂„Å™„Éù„Éº„Ç∫
        utterance.preUtteranceDelay = isFirst ? 0.1 : 0.25
        utterance.postUtteranceDelay = isLast ? 0.15 : 0.1

        return utterance
    }

    /// Ë®ÄË™û„Å´ÊúÄÈÅ©„Å™Èü≥Â£∞„ÇíÂèñÂæóÔºàEnhancedÈü≥Â£∞„ÇíÂÑ™ÂÖàÔºâ
    private func getBestVoice(for language: String) -> AVSpeechSynthesisVoice? {
        if let cached = voiceCache[language] {
            return cached
        }

        let voices = AVSpeechSynthesisVoice.speechVoices()
        let languagePrefix = String(language.prefix(2))

        // EnhancedÈü≥Â£∞„ÇíÂÑ™ÂÖà
        let enhancedVoices = voices.filter { voice in
            voice.language.hasPrefix(languagePrefix) && voice.quality == .enhanced
        }

        if let enhanced = enhancedVoices.first {
            voiceCache[language] = enhanced
            print("üé§ EnhancedÈü≥Â£∞: \(enhanced.name)")
            return enhanced
        }

        // ÈÄöÂ∏∏Èü≥Â£∞
        if let normal = voices.first(where: { $0.language.hasPrefix(languagePrefix) }) {
            voiceCache[language] = normal
            return normal
        }

        return AVSpeechSynthesisVoice(language: language)
    }

    /// Ë®ÄË™û„Å´Âøú„Åò„Åü„Éî„ÉÉ„ÉÅ„ÇíÂèñÂæó
    private func getPitch(for language: String) -> Float {
        let languagePrefix = String(language.prefix(2))
        switch languagePrefix {
        case "ja": return 1.0
        case "zh": return 1.03
        case "ko": return 1.0
        case "fr", "it": return 1.02
        case "de": return 0.98
        default: return 1.0
        }
    }

    /// „ÉÜ„Ç≠„Çπ„Éà„ÇíÊñáÂçò‰Ωç„ÅßÂàÜÂâ≤
    private func splitIntoSentences(text: String, language: String) -> [String] {
        let languagePrefix = String(language.prefix(2))

        let delimiters: CharacterSet
        switch languagePrefix {
        case "ja", "zh":
            delimiters = CharacterSet(charactersIn: "„ÄÇÔºÅÔºü!?Ôºé")
        case "ar", "fa", "he":
            delimiters = CharacterSet(charactersIn: ".!?ÿåÿü")
        default:
            delimiters = CharacterSet(charactersIn: ".!?")
        }

        var sentences: [String] = []
        var current = ""

        for char in text {
            current.append(char)
            if let scalar = char.unicodeScalars.first, delimiters.contains(scalar) {
                let trimmed = current.trimmingCharacters(in: .whitespacesAndNewlines)
                if !trimmed.isEmpty {
                    sentences.append(trimmed)
                }
                current = ""
            }
        }

        let remaining = current.trimmingCharacters(in: .whitespacesAndNewlines)
        if !remaining.isEmpty {
            sentences.append(remaining)
        }

        return sentences.isEmpty ? [text] : sentences
    }

    private func configureAudioSession() {
        do {
            let audioSession = AVAudioSession.sharedInstance()
            try audioSession.setCategory(.playback, mode: .spokenAudio, options: [.duckOthers])
            try audioSession.setActive(true)
        } catch {
            print("Audio session error: \(error)")
        }
    }
}

// MARK: - AVSpeechSynthesizerDelegate

extension TextToSpeechService: AVSpeechSynthesizerDelegate {
    nonisolated func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didStart utterance: AVSpeechUtterance) {
        Task { @MainActor in
            self.isSpeaking = true
        }
    }

    nonisolated func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didFinish utterance: AVSpeechUtterance) {
        Task { @MainActor in
            if !synthesizer.isSpeaking {
                self.isSpeaking = false
            }
        }
    }

    nonisolated func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didCancel utterance: AVSpeechUtterance) {
        Task { @MainActor in
            self.isSpeaking = false
        }
    }
}

// MARK: - AVAudioPlayerDelegate

extension TextToSpeechService: AVAudioPlayerDelegate {
    nonisolated func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        Task { @MainActor in
            self.isSpeaking = false
            print("üîä Èü≥Â£∞ÂÜçÁîüÂÆå‰∫Ü")
        }
    }

    nonisolated func audioPlayerDecodeErrorDidOccur(_ player: AVAudioPlayer, error: Error?) {
        Task { @MainActor in
            self.isSpeaking = false
            print("‚ùå Èü≥Â£∞„Éá„Ç≥„Éº„Éâ„Ç®„É©„Éº: \(error?.localizedDescription ?? "‰∏çÊòé")")
        }
    }
}
